# -*- coding: utf-8 -*-
"""Volatilidad LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y6bhNC5Wcs8odGKI3Jv3HeaBhUi0mRCA
"""

# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PHOs4Jbx4o1mxxpwF3IKm3f5_BWyVkIF
"""

from google.colab import drive
drive.mount('/content/drive/', force_remount=True)

from keras.models import Sequential
from keras.layers import LSTM, Dense

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

np.random.seed(4)

#Importando el dataset
path_dataset = '/content/drive/MyDrive/Dataset/'
dataset = pd.read_csv("".join([path_dataset,"SP500Volatilidad.csv"]))
#datasetval = pd.read_csv("".join([path_dataset,"Datosval.csv"]))
print(dataset)
#print(dataset.columns)
#dataset.head()


#Normalización
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM

#
# Funciones auxiliares
#
def graficar_predicciones(real, prediccion):
    #plt.plot(real[0:len(prediccion)],color='red', label='Valor real de Indice')
    plt.plot(real,color='red', label='Valor real de Indice')
    plt.plot(prediccion, color='blue', label='Predicción del Indice')
    #plt.ylim(1.1 * np.min(prediccion)/2, 1.1 * np.max(prediccion))
    plt.xlabel('Tiempo')
    plt.ylabel('Valor del Indice')
    plt.legend()
    plt.show()

#
# Sets de entrenamiento y validación
set_entrenamiento = dataset[:16700].iloc[:,1:2]
set_validacion = dataset[16701:].iloc[:,1:2]

#print (set_entrenamiento)
#print (set_validacion)

# Normalización del set de entrenamiento
sc = MinMaxScaler(feature_range=(0,1))
set_entrenamiento_escalado = sc.fit_transform(set_entrenamiento)

print (set_entrenamiento_escalado.shape)

###########################################################################################################
### Lectura de bloques de 60 días y se estima el día siguiente (amplitud:time:step).
### Se dividen los datos en 60 en 60: X_train
### La predicción es Y: el día siguiente: Y_train
###########################################################################################################

time_step = 250
X_train = []
Y_train = []
# Tamaño del dataset de entrenamento
m = len(set_entrenamiento_escalado)

for i in range(time_step,m):
    # X: bloques de "time_step" datos: 0-time_step, 1-time_step+1, 2-time_step+2, etc (días de 1 a 60)
    X_train.append(set_entrenamiento_escalado[i-time_step:i,0])
    # Y: el siguiente dato (día 61)
    Y_train.append(set_entrenamiento_escalado[i,0])

X_train, Y_train = np.array(X_train), np.array(Y_train)
print("Dimensión de X_train", X_train.shape, np.array(X_train).shape)
print("Dimensión de Y_train", np.array(Y_train).shape)
print(Y_train)
# Reshape X_train para que se ajuste al modelo en Keras
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

#####################################################################
### Creación de la Red LSTM
#####################################################################

# Parámetros
# Cada época se coge de 32 en 32
epochs = 300
batch_size= 21

dim_entrada = (X_train.shape[1],1)
dim_salida = 1
na = 50
print(X_train.shape)
modelo = Sequential()
modelo.add(LSTM(units=na, input_shape=dim_entrada))
modelo.add(Dense(units=dim_salida))
modelo.compile(optimizer='rmsprop', loss='mse')
modelo.fit(X_train,Y_train,batch_size, epochs)



#####################################################################
# Validación (predicción del valor de las acciones)
######################################################################
x_test = set_validacion.values
x_test = sc.transform(x_test)

X_test = []
for i in range(time_step,len(x_test)):
    X_test.append(x_test[i-time_step:i,0])
X_test = np.array(X_test)
print("Dimensión de X_test",X_test.shape,(X_test.shape[0],X_test.shape[1]))
print("Dimensión de X_test",(X_test.shape[0],X_test.shape[1]))
#X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1]),1)

print("Dimensión de X_test",X_test.shape)

prediccion = modelo.predict(X_test)


prediccion = sc.inverse_transform(prediccion)

# Graficar resultados
graficar_predicciones(set_validacion.values,prediccion)

import numpy as  np

actual =set_validacion.values[:500]
pred = prediccion[:500]

def mse (actual, pred):
    actual, pred = np.array (actual), np.array (pred)
    return np.square (np.subtract (actual, pred)). mean ()

mse (actual, pred)

def graficar_predicciones(real, prediccion):
    plt.plot(real[0:len(prediccion)],color='red', label='Valor real')
    plt.plot(prediccion, color='blue', label='Predicción')
    #plt.ylim(1.1 * np.min(prediccion)/2, 1.1 * np.max(prediccion))
    plt.xlabel('Tiempo')
    plt.ylabel('Valor del Indice')
    plt.legend()
    plt.show()

# Graficar resultados
graficar_predicciones(set_validacion.values,prediccion)

from sklearn import metrics

score = np.sqrt(metrics.mean_squared_error(prediccion,set_validacion.values))
print("Score (RMSE): {}".format(score))